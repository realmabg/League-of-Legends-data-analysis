{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Vision Score Statistical Analysis\n",
    "\n",
    "**Name(s)**: Adrian Kong and Borngreat Omoma-Edosa\n",
    "\n",
    "**Website Link**: https://realmabg.github.io/League-of-Legends-data-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, Binarizer, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from dsc80_utils import * # Feel free to uncomment and use this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How effeective is having a higher vision score than having the other team in getting kills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/k_06cnf50jv837zrzkdd_xxc0000gn/T/ipykernel_61486/3671588007.py:9: DtypeWarning:\n",
      "\n",
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/var/folders/28/k_06cnf50jv837zrzkdd_xxc0000gn/T/ipykernel_61486/3671588007.py:9: DtypeWarning:\n",
      "\n",
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/var/folders/28/k_06cnf50jv837zrzkdd_xxc0000gn/T/ipykernel_61486/3671588007.py:9: DtypeWarning:\n",
      "\n",
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n",
      "/var/folders/28/k_06cnf50jv837zrzkdd_xxc0000gn/T/ipykernel_61486/3671588007.py:9: DtypeWarning:\n",
      "\n",
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gets data from each year\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for x in np.arange(2014, 2026):\n",
    "\n",
    "    csv_name = f\"data/{x}_LoL_esports_match_data_from_OraclesElixir.csv\"\n",
    "\n",
    "    df = pd.read_csv(csv_name)\n",
    "\n",
    "    data = pd.concat([data, df])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHooses which columns we want\n",
    "\n",
    "vision_columns = [\"gameid\",\"side\",\"assists\",\"result\",'wardsplaced', 'wpm', 'wardskilled', 'wcpm', \"kills\",\n",
    "       'controlwardsbought', 'visionscore', 'vspm',\"position\",\"gamelength\",\"year\",\"url\",\"league\",\"datacompleteness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vision_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m vision_data \u001b[38;5;241m=\u001b[39m vision_data[vision_columns]\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6815\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/miniforge3/envs/dsc80/lib/python3.12/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vision_data = data.copy()\n",
    "vision_data = vision_data[vision_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameid</th>\n",
       "      <th>side</th>\n",
       "      <th>assists</th>\n",
       "      <th>result</th>\n",
       "      <th>wardsplaced</th>\n",
       "      <th>wpm</th>\n",
       "      <th>wardskilled</th>\n",
       "      <th>wcpm</th>\n",
       "      <th>kills</th>\n",
       "      <th>controlwardsbought</th>\n",
       "      <th>visionscore</th>\n",
       "      <th>vspm</th>\n",
       "      <th>position</th>\n",
       "      <th>gamelength</th>\n",
       "      <th>year</th>\n",
       "      <th>url</th>\n",
       "      <th>league</th>\n",
       "      <th>datacompleteness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRLH3/33</td>\n",
       "      <td>Blue</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>top</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>http://matchhistory.na.leagueoflegends.com/en/...</td>\n",
       "      <td>EU LCS</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRLH3/33</td>\n",
       "      <td>Blue</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>jng</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>http://matchhistory.na.leagueoflegends.com/en/...</td>\n",
       "      <td>EU LCS</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRLH3/33</td>\n",
       "      <td>Blue</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>mid</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>http://matchhistory.na.leagueoflegends.com/en/...</td>\n",
       "      <td>EU LCS</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>LOLTMNT03_201606</td>\n",
       "      <td>Red</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>sup</td>\n",
       "      <td>1931</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPLOL</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>LOLTMNT03_201606</td>\n",
       "      <td>Blue</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>13</td>\n",
       "      <td>23.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>6.62</td>\n",
       "      <td>team</td>\n",
       "      <td>1931</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPLOL</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17531</th>\n",
       "      <td>LOLTMNT03_201606</td>\n",
       "      <td>Red</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>18</td>\n",
       "      <td>26.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>7.83</td>\n",
       "      <td>team</td>\n",
       "      <td>1931</td>\n",
       "      <td>2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPLOL</td>\n",
       "      <td>complete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1013856 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gameid  side  assists  result  wardsplaced   wpm  \\\n",
       "0              TRLH3/33  Blue       13       1         13.0  0.41   \n",
       "1              TRLH3/33  Blue       14       1         12.0  0.37   \n",
       "2              TRLH3/33  Blue        7       1         12.0  0.37   \n",
       "...                 ...   ...      ...     ...          ...   ...   \n",
       "17529  LOLTMNT03_201606   Red       10       1         52.0  1.62   \n",
       "17530  LOLTMNT03_201606  Blue       41       0        100.0  3.11   \n",
       "17531  LOLTMNT03_201606   Red       40       1         93.0  2.89   \n",
       "\n",
       "       wardskilled  wcpm  kills  controlwardsbought  visionscore  vspm  \\\n",
       "0              0.0  0.00      3                 0.0          0.0  0.00   \n",
       "1              0.0  0.00      0                 1.0          0.0  0.00   \n",
       "2              3.0  0.09     10                 0.0          0.0  0.00   \n",
       "...            ...   ...    ...                 ...          ...   ...   \n",
       "17529         11.0  0.34      3                13.0        114.0  3.54   \n",
       "17530         34.0  1.06     13                23.0        213.0  6.62   \n",
       "17531         39.0  1.21     18                26.0        252.0  7.83   \n",
       "\n",
       "      position  gamelength  year  \\\n",
       "0          top        1924  2014   \n",
       "1          jng        1924  2014   \n",
       "2          mid        1924  2014   \n",
       "...        ...         ...   ...   \n",
       "17529      sup        1931  2025   \n",
       "17530     team        1931  2025   \n",
       "17531     team        1931  2025   \n",
       "\n",
       "                                                     url  league  \\\n",
       "0      http://matchhistory.na.leagueoflegends.com/en/...  EU LCS   \n",
       "1      http://matchhistory.na.leagueoflegends.com/en/...  EU LCS   \n",
       "2      http://matchhistory.na.leagueoflegends.com/en/...  EU LCS   \n",
       "...                                                  ...     ...   \n",
       "17529                                                NaN   LPLOL   \n",
       "17530                                                NaN   LPLOL   \n",
       "17531                                                NaN   LPLOL   \n",
       "\n",
       "      datacompleteness  \n",
       "0             complete  \n",
       "1             complete  \n",
       "2             complete  \n",
       "...                ...  \n",
       "17529         complete  \n",
       "17530         complete  \n",
       "17531         complete  \n",
       "\n",
       "[1013856 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only gets team data\n",
    "\n",
    "team_vision_data = vision_data.copy()\n",
    "team_vision_data = team_vision_data[team_vision_data[\"position\"]==\"team\"]\n",
    "team_vision_data = team_vision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes irrelevant/NA data\n",
    "\n",
    "team_vision_data = team_vision_data[team_vision_data[\"visionscore\"].isna() == False]\n",
    "team_vision_data = team_vision_data[team_vision_data[\"visionscore\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes more_vision and more_kills columns (explained in website)\n",
    "\n",
    "max_vision = team_vision_data.groupby('gameid')['visionscore'].transform('max')\n",
    "\n",
    "\n",
    "team_vision_data['more_vision'] = (team_vision_data['visionscore'] == max_vision).astype(int)\n",
    "\n",
    "for gameid, group in team_vision_data.groupby('gameid'):\n",
    "        max_kills = group['visionscore'].max()\n",
    "        if (group['visionscore'] == max_kills).sum() > 1:\n",
    "            team_vision_data.loc[group.index, 'more_vision'] = 0  \n",
    "\n",
    "\n",
    "\n",
    "max_vision = team_vision_data.groupby('gameid')['kills'].transform('max')\n",
    "\n",
    "\n",
    "team_vision_data['more_kills'] = (team_vision_data['kills'] == max_vision).astype(int)\n",
    "\n",
    "for gameid, group in team_vision_data.groupby('gameid'):\n",
    "        max_kills = group['kills'].max()\n",
    "        if (group['kills'] == max_kills).sum() > 1:\n",
    "            team_vision_data.loc[group.index, 'more_kills'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vision_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes certain columns to boolean type\n",
    "\n",
    "team_vision_data[\"result\"] = team_vision_data[\"result\"].astype(\"bool\")\n",
    "team_vision_data[\"more_vision\"] = team_vision_data[\"more_vision\"].astype(\"bool\")\n",
    "team_vision_data[\"more_kills\"] = team_vision_data[\"more_kills\"].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks column types\n",
    "\n",
    "for column in team_vision_data.columns:\n",
    "    print(type(team_vision_data[column].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vision_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes histogram for distribution of team's kills\n",
    "\n",
    "fig = px.histogram(\n",
    "    team_vision_data, \n",
    "    x=\"kills\", \n",
    "    nbins=100,  \n",
    "    title=\"Distribution of Team's Total Kills\",\n",
    "    labels={\"kills\": \"Number of Kills\"},\n",
    "    opacity=0.75,  \n",
    "    color_discrete_sequence=[\"steelblue\"]  \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    bargap=0.1, \n",
    "    xaxis_title=\"Kills\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    template=\"plotly_white\"  \n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('univariate_graph_team_kills.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes histogram for distribution of team's visionscore\n",
    "\n",
    "fig = px.histogram(\n",
    "    team_vision_data, \n",
    "    x=\"visionscore\", \n",
    "    nbins=100,  \n",
    "    title=\"Distribution of Team's Vision Score\",\n",
    "    labels={\"visionscore\": \"Number of Kills\"},\n",
    "    opacity=0.75,  \n",
    "    color_discrete_sequence=[\"steelblue\"]  \n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    bargap=0.1, \n",
    "    xaxis_title=\"Vision score\",\n",
    "    yaxis_title=\"Frequency\",\n",
    "    template=\"plotly_white\"  \n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_html('univariate_graph_visionscore.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins_df = team_vision_data[team_vision_data[\"more_vision\"] == 1]\n",
    "\n",
    "\n",
    "counts = wins_df[\"more_kills\"].value_counts()\n",
    "\n",
    "labelling = {True: \"Team gets more kills\", False: \"Team gets less kills\"}  \n",
    "\n",
    "\n",
    "new_index = []\n",
    "for i in counts.index:\n",
    "    if isinstance(i, bool):\n",
    "        new_index.append(labelling[i])\n",
    "    else:\n",
    "        new_index.append(i)\n",
    "\n",
    "counts.index = new_index\n",
    "\n",
    "\n",
    "\n",
    "biv1 = px.pie(values=counts.values, names=counts.index, title=\"Does the team get more kills when they have more vision?\")\n",
    "\n",
    "biv1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a graph about teams winning when they have more vision\n",
    "\n",
    "wins_df = team_vision_data[team_vision_data[\"more_vision\"] == 1]\n",
    "\n",
    "\n",
    "counts = wins_df[\"result\"].value_counts()\n",
    "\n",
    "labelling = {True: \"Win\", False: \"Loss\"}  \n",
    "\n",
    "\n",
    "new_index = []\n",
    "for i in counts.index:\n",
    "    if isinstance(i, bool):\n",
    "        new_index.append(labelling[i])\n",
    "    else:\n",
    "        new_index.append(i)\n",
    "\n",
    "counts.index = new_index\n",
    "\n",
    "\n",
    "color_map = {\"Win\": \"green\", \"Loss\": \"red\"}\n",
    "\n",
    "biv1 = px.pie(\n",
    "    values=counts.values,\n",
    "    names=counts.index,\n",
    "    title=\"Does a team win when they have more vision?\",\n",
    "    color=counts.index,  # Color by the labels (Win, Loss)\n",
    "    color_discrete_map=color_map  # Map Win to green and Loss to red\n",
    ")\n",
    "\n",
    "\n",
    "# biv1 = px.pie(values=counts.values, names=counts.index, title=\"Does a team win when they have more vision?\")\n",
    "\n",
    "biv1.show()\n",
    "\n",
    "fig.write_html('bivariate_result_vision.html', include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Interesting Aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of stats based on team with more kills\n",
    "\n",
    "\n",
    "agg = team_vision_data.groupby(\"more_kills\").sum()\n",
    "\n",
    "agg= agg.drop(columns=[\"gameid\",\"side\",\"position\",\"url\",\"league\",\"datacompleteness\",\"year\",\"gamelength\"])\n",
    "\n",
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of stats based on team with more vision\n",
    "\n",
    "agg = team_vision_data.groupby(\"more_vision\").sum()\n",
    "\n",
    "agg= agg.drop(columns=[\"gameid\",\"side\",\"position\",\"url\",\"league\",\"datacompleteness\",\"year\",\"gamelength\"])\n",
    "\n",
    "agg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "team_vision_data[team_vision_data[\"url\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column that says if there is a url\n",
    "\n",
    "team_vision_data[\"url_missing\"] = team_vision_data[\"url\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts based on year and url missing\n",
    "\n",
    "url_pivot1 = team_vision_data.pivot_table(index='url_missing', columns='year', aggfunc='size',fill_value=0)\n",
    "url_pivot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total counts\n",
    "\n",
    "url_pivot2 = pd.pivot_table(team_vision_data,index=\"url_missing\",values=\"league\",aggfunc=len, fill_value=0)\n",
    "url_pivot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_pivot = url_pivot1.div(url_pivot2['league'], axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvd_observed = url_pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "tvd_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion table, along with making the format better\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "def format_value(x):\n",
    "    if abs(x) < 1e-6:  # Adjust the threshold as needed\n",
    "        return '0'\n",
    "    else:\n",
    "        return '{:.5f}'.format(x)\n",
    "\n",
    "url_pivot = url_pivot.applymap(format_value)\n",
    "url_pivot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format for markdown\n",
    "\n",
    "markdown_table = url_pivot.copy()\n",
    "\n",
    "markdown_table = markdown_table.rename(columns={False: f'url_missing = False', True: f'url_missing = True'})\n",
    "\n",
    "markdown_table = markdown_table.to_markdown()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(markdown_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Hypothesis: Distribution of year when url is missing is the same as the distribution of year when url is not missing.\n",
    "\n",
    "# Alternative Hypothesis: Distribution of year when url is missing is NOT same as the distribution of year when url is not missing.\n",
    "\n",
    "# sample stat: 0.855\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df = team_vision_data.copy()\n",
    "smaller_df = smaller_df[[\"year\",\"url_missing\"]]\n",
    "smaller_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvd_stats = []\n",
    "\n",
    "for _ in np.arange(100):\n",
    "    smaller_df[\"url_shuffled\"] = np.random.permutation(smaller_df[\"url_missing\"])\n",
    "    pivoted = (\n",
    "        smaller_df\n",
    "        .pivot_table(index='url_shuffled', columns='year', aggfunc='size',fill_value=0)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    permutated_table = pivoted.div(url_pivot2['league'], axis=0).T\n",
    "    \n",
    "    tvd = permutated_table.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "    tvd_stats.append(tvd)\n",
    "\n",
    "tvd_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(tvd_stats), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the TVD')\n",
    "fig.add_vline(x=tvd_observed, line_color='red', line_width=2, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(tvd_observed, 2)}</span>',\n",
    "                   x=2.5 * tvd_observed, showarrow=False, y=0.16)\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(tvd_stats) >= tvd_observed).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pivot.plot(kind='barh', title='Gender by Missingness of Child Height (MCAR Example)', barmode='group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reject the null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vision_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(column):\n",
    "    print(column)\n",
    "    pivot1 = team_vision_data.pivot_table(index='url_missing', columns=f'{column}', aggfunc='size',fill_value=0)\n",
    "    pivot2 = pd.pivot_table(team_vision_data,index=\"url_missing\",values=f'{column}',aggfunc=len, fill_value=0)\n",
    "    pivot = pivot1.div(pivot2[column], axis=0).T\n",
    "    observed_tvd = pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "    df_smaller = team_vision_data.copy()\n",
    "    df_smaller = df_smaller[[\"url_missing\",column]]\n",
    "\n",
    "    tvd_stats2 = []\n",
    "\n",
    "    for _ in np.arange(1000):\n",
    "        df_smaller[\"url_shuffled\"] = np.random.permutation(df_smaller[\"url_missing\"])\n",
    "        pivoted = (\n",
    "        df_smaller\n",
    "        .pivot_table(index='url_shuffled', columns=f'{column}', aggfunc='size',fill_value=0)\n",
    "    )\n",
    "    \n",
    "    \n",
    "        permutated_table = pivoted.div(pivot2[column], axis=0).T\n",
    "    \n",
    "        tvd = permutated_table.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "        tvd_stats2.append(tvd)\n",
    "\n",
    "    return (column, (np.array(tvd_stats2) >= observed_tvd).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot1 = team_vision_data.pivot_table(index='url_missing', columns= \"more_vision\", aggfunc='size',fill_value=0)\n",
    "pivot2 = pd.pivot_table(team_vision_data,index=\"url_missing\",values= \"more_vision\",aggfunc=len, fill_value=0)\n",
    "pivot = pivot1.div(pivot2[\"more_vision\"], axis=0).T\n",
    "observed_tvd = pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "\n",
    "df_smaller = team_vision_data.copy()\n",
    "df_smaller = df_smaller[[\"url_missing\",\"more_vision\"]]\n",
    "\n",
    "\n",
    "tvd_stats2 = []\n",
    "\n",
    "for _ in np.arange(1000):\n",
    "        df_smaller[\"url_shuffled\"] = np.random.permutation(df_smaller[\"url_missing\"])\n",
    "        pivoted = (\n",
    "        df_smaller\n",
    "        .pivot_table(index='url_shuffled', columns=\"more_vision\", aggfunc='size',fill_value=0)\n",
    ")\n",
    "    \n",
    "    \n",
    "        permutated_table = pivoted.div(pivot2[\"more_vision\"], axis=0).T\n",
    "    \n",
    "        tvd = permutated_table.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "        tvd_stats2.append(tvd)\n",
    "\n",
    "(np.array(tvd_stats2) >= observed_tvd).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.diff(axis=1).iloc[:, -1].abs().sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper(\"more_vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Hypothesis: Distribution of vision score when url is missing is the same as the distribution of vision score when url is not missing.\n",
    "\n",
    "# Alternative Hypothesis: Distribution of vision score when url is missing is NOT same as the distribution of vision score when url is not missing.\n",
    "\n",
    "# sample stat: 0.0015\n",
    "\n",
    "# Fail to reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(tvd_stats2), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the TVD')\n",
    "fig.add_vline(x=observed_tvd, line_color='red', line_width=2, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 4)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hyphotesis: The distribution of kills for a team with the higher vision score in a game is the same as the team that has the lower vision score.\n",
    "\n",
    "Alternate Hyphotesis: The distribution of kills for the team with the higher vision score is NOT the same as the team that has the lower vision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "\n",
    "# Null: The distribution of kills for a team with the higher vision score in a game is the same as the team that has the lower vision score.\n",
    "\n",
    "\n",
    "# Alternate: The distribution of kills for the team with the higher vision score is NOT the same as the team that has the lower vision score.\n",
    "\n",
    "\n",
    "# Absolute mean difference between kills in teams with higher vision and kills in teams with lower vision,\n",
    "\n",
    "#test statistic: 0.4150174636183205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot1 = team_vision_data.pivot_table(index='kills', columns= \"more_vision\", aggfunc='size',fill_value=0)\n",
    "pivot1 = pivot1 / pivot1.sum()\n",
    "observed_tvd = pivot1.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "observed_tvd\n",
    "pivot1 = team_vision_data.pivot_table(index='kills', columns= \"more_vision\", aggfunc='size',fill_value=0)\n",
    "pivot1 = pivot1 / pivot1.sum()\n",
    "observed_tvd = pivot1.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df_smaller = team_vision_data.copy()\n",
    "df_smaller = df_smaller[[\"more_vision\",\"kills\"]]\n",
    "\n",
    "\n",
    "tvd_stats3 = []\n",
    "\n",
    "for _ in np.arange(1000):\n",
    "        df_smaller[\"vision_shuffled\"] = np.random.permutation(df_smaller[\"more_vision\"])\n",
    "        pivoted = (\n",
    "        df_smaller\n",
    "        .pivot_table(index='kills', columns=\"vision_shuffled\", aggfunc='size',fill_value=0)\n",
    ")\n",
    "        pivoted = pivoted / pivoted.sum()\n",
    "\n",
    "    \n",
    "        tvd = pivoted.diff(axis=1).iloc[:, -1].abs().sum() / 2\n",
    "        tvd_stats3.append(tvd)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"P-value: {(np.array(tvd_stats) >= tvd_observed).mean():.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(pd.DataFrame(tvd_stats3), x=0, nbins=50, histnorm='probability', \n",
    "                   title='Empirical Distribution of the TVD')\n",
    "fig.add_vline(x=observed_tvd, line_color='red', line_width=2, opacity=1)\n",
    "fig.add_annotation(text=f'<span style=\"color:red\">Observed TVD = {round(observed_tvd, 4)}</span>',\n",
    "                   x=2.5 * observed_tvd, showarrow=False, y=0.16)\n",
    "fig.update_layout(yaxis_range=[0, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we accurately predict a team's vision score based solely on their in-game performance statistics?\n",
    "\n",
    "For our prediction model, we will perform necessary preprocessing steps such as dropping non-informative or metadata columns like gameid and url. This ensures that our model leverages only the relevant in-game statistics.\n",
    "\n",
    "To address this question, we will frame the problem as a regression task where the vision score is treated as a continuous variable. Our dataset includes the following columns:\n",
    "assists, result, wardsplaced, wpm, wardskilled, wcpm, kills, controlwardsbought, visionscore, gamelength, more_kills, and more_vision\n",
    "\n",
    "To mitigate overfitting, the data will be split into 75% training and 25% test sets. Our model’s performance will be evaluated using regression metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and the R² score. These metrics will help us understand the predictive accuracy and the variance explained by our model.\n",
    "\n",
    "At the time of prediction, the only available information will be the in-game performance statistics (e.g., assists, wards placed, ward kills, kills, control wards bought, etc.), allowing the model to generate an estimated vision score. This predictive insight can then be used to further understand a player’s contribution to vision control and overall team strategy.\n",
    "\n",
    "By addressing this prediction problem, we aim to quantify the impact of in-game performance on vision score, providing a valuable tool for game analysis and strategic planning in League of Legends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_df = team_vision_data.drop(columns=['side', 'year', 'league', 'url','datacompleteness','position','vspm','gameid','url_missing'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline model, we used a linear regression, with the following features wardsplaced, wpm, wardskilled, wcpm, controlwardsbought. My assumption is that the most direct inputs to a vision score are the actions related to placing and managing wards. The features are quantitative. We utilized StandardScaler Transformer to transform them into standard scale, becasue each match has different time length, and therefore the statistics could seem really different without being standardized. \n",
    "\n",
    "We also used Polynomial Features to fine a hyperameter that best fit the model. After fitting the model, our R squared score on the training data was 0.9102. Though our accuracy is high the RSME on the training data was 18.3220, which is not very good. Our R squared score on the test data was 0.9078, which means our model has low variance. The RSME on the test data was 22.4480. Our model still has large improvement space, and we will improve it by adding more features and using a random forest regressor, and tuning hyperparameters in the next section because it will capture complex, non-linear interactions without needing to manually generate polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = predict_df.drop(columns=['assists','result','kills','visionscore','gamelength','more_vision','more_kills'], axis=1)\n",
    "y = predict_df['visionscore']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the hyperparameter\n",
    "\n",
    "errs_df = pd.DataFrame()\n",
    "\n",
    "for d in tqdm(range(1, 6)):\n",
    "    pl= make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(d),\n",
    "        LinearRegression(),\n",
    "    )\n",
    "    \n",
    "    errs = cross_val_score(pl, X_train, y_train, \n",
    "                           cv=KFold(5, shuffle=True, random_state=1), scoring='neg_root_mean_squared_error')\n",
    "    errs_df[f'Deg {d}'] = -errs # Negate to turn positive (sklearn computed negative RMSE).\n",
    "    \n",
    "errs_df.index = [f'Fold {i}' for i in range(1, 6)]\n",
    "errs_df.index.name = 'Validation Fold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_df.mean().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(4),\n",
    "        LinearRegression(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basline_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_train, basline_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_test, basline_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Final model, we shifted from a polynomial linear regression approach to a Random Forest regressor to better capture complex non-linear interactions among our features. Our dataset includes both categorical variables (such as result, more_vision, and more_kills) and quantitative features (like assists, wardsplaced, wpm, wardskilled, wcpm, kills, controlwardsbought, gamelength, among others). We used a preprocessing pipeline where the categorical features were transformed using OneHotEncoder (with the first category dropped) and the numerical features were standardized using StandardScaler. This ensures that differences in match duration and varying scales among features do not skew the model's performance.\n",
    "\n",
    "To improve model performance, we implemented hyperparameter tuning using GridSearchCV. We set up a grid that explored combinations of three key hyperparameters for the Random Forest regressor: the number of trees (n_estimators), the maximum depth of the trees (max_depth), and the minimum number of samples required to split a node (min_samples_split). The grid search was conducted with 5-fold cross-validation (with shuffling enabled for more robust sampling) and used negative root mean squared error (RMSE) as the scoring metric.\n",
    "\n",
    "Given the size of our dataset (approximately 100,000 rows), we opted to perform the initial hyperparameter tuning on a smaller subset (50,000 rows). This subset allowed us to efficiently search for the best hyperparameters without the extensive computational time required for the full dataset. On this subset, the grid search identified the best hyperparameters as follows: max_depth of 10, min_samples_split of 5, and n_estimators of 200, resulting in a cross-validated RMSE of around 19.0761 and a test RMSE of approximately 18.9855.\n",
    "\n",
    "With these promising results from the subset, we applied the tuned hyperparameters to a pipeline re-fitted on the full training data. This approach should leverage the model's ability to capture non-linearities and complex feature interactions, ultimately enhancing the prediction of the team's vision score compared to our baseline model. Using the best parameter the test dataset RMSE was 18.8683, the train dataset R^2 was 0.9438, and the test R^2 was 0.9348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary that maps names to Pipeline objects.\n",
    "n=3\n",
    "select = FunctionTransformer(lambda x: x)\n",
    "pipes = {\n",
    "    'wardsplaced + wardskilled': make_pipeline(\n",
    "        make_column_transformer( (select, ['wardsplaced', 'wardskilled']) ),\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(n),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'wardsplaced + wardskilled + controlwardsbought + gamelength': make_pipeline(\n",
    "        make_column_transformer( (select, ['wardsplaced', 'wardskilled','controlwardsbought','gamelength']) ),\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(n),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'all ward + controlwardsbought + gamelength': make_pipeline(\n",
    "        make_column_transformer( (select, ['wardsplaced', 'wardskilled','controlwardsbought','gamelength','wcpm','wpm']) ),\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(n),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "    'All columns': make_pipeline(\n",
    "       make_column_transformer(\n",
    "           (OneHotEncoder(drop='first'), ['result', 'more_vision', 'more_kills']),\n",
    "           remainder='passthrough',\n",
    "           force_int_remainder_cols=False,\n",
    "           ),\n",
    "        StandardScaler(),\n",
    "        PolynomialFeatures(n),\n",
    "        LinearRegression(),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df = pd.DataFrame()\n",
    "\n",
    "for pipe in pipes:\n",
    "    errs = cross_val_score(pipes[pipe], X_train, y_train,\n",
    "                           cv=KFold(5, shuffle=True, random_state=1), scoring='neg_root_mean_squared_error')\n",
    "    pipe_df[pipe] = -errs\n",
    "    \n",
    "pipe_df.index = [f'Fold {i}' for i in range(1, 6)]\n",
    "pipe_df.index.name = 'Validation Fold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a smaller subset (e.g., 10,000 rows) from your dataset\n",
    "subset_df = predict_df.sample(n=50000, random_state=1)\n",
    "\n",
    "# Define features and target variable for the subset\n",
    "X_sub = subset_df.drop('visionscore', axis=1)\n",
    "y_sub = subset_df['visionscore']\n",
    "\n",
    "# Split the subset into training and testing sets\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X_sub, y_sub, test_size=0.2, random_state=1)\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['result', 'more_vision', 'more_kills']\n",
    "numerical_cols = [col for col in X_sub.columns if col not in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessor for both categorical and numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline that applies preprocessing and then fits a Random Forest regressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=1))\n",
    "])\n",
    "\n",
    "# Define a grid of hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 5, 10],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV with 5-fold cross-validation and negative RMSE scoring\n",
    "grid_search_sub = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the subset's training data\n",
    "grid_search_sub.fit(X_train_sub, y_train_sub)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the best hyperparameters and corresponding cross-validated RMSE for the subset\n",
    "print(\"Best parameters on subset:\", grid_search_sub.best_params_)\n",
    "print(\"Best CV RMSE on subset:\", -grid_search_sub.best_score_)\n",
    "\n",
    "# Evaluate the best model from the subset on its test set\n",
    "y_pred_sub = grid_search_sub.predict(X_test_sub)\n",
    "test_rmse_sub = np.sqrt(mean_squared_error(y_test_sub, y_pred_sub))\n",
    "print(\"Test RMSE on subset:\", test_rmse_sub)\n",
    "\n",
    "# After tuning on the subset, you can apply these best parameters to a new pipeline \n",
    "# and re-fit on the full training data if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'predict_df' is your DataFrame\n",
    "# Define features and target variable\n",
    "X = predict_df.drop('visionscore', axis=1)\n",
    "y = predict_df['visionscore']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['result', 'more_vision', 'more_kills']\n",
    "numerical_cols = [col for col in X.columns if col not in categorical_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline: apply OneHotEncoder for categorical features and StandardScaler for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline that first preprocesses the data then applies a Random Forest regressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=1))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters for the Random Forest\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_depth': [None, 5, 10],\n",
    "    'regressor__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV with 5-fold cross-validation and negative RMSE scoring\n",
    "\n",
    "\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the best hyperparameters and corresponding cross-validated RMSE\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Train RMSE:\", -grid_search.score(X_train, y_train))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE:\", test_rmse)\n",
    "\n",
    "print(\"Train R^2:\", r2_score(y_train, grid_search.predict(X_train)))\n",
    "\n",
    "print(\"Test R^2:\",r2_score(y_test, grid_search.predict(X_test)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to assess if our model is fair among different groups. The question we are trying to answer here is: “does my model perform worse on teams that lost than it does for teams that won ?” To answer this question, we performed a permutation test and examined the result of the difference in accuracy between the two groups.\n",
    "\n",
    "The group X represents the teams that lost, and group Y represents the teams that won. Our evaluation metric is the difference in the R^2 between each group, and the significance level is 0.05.\n",
    "\n",
    "The followings are our hypothesis:\n",
    "\n",
    "Null hypothesis: Our model is fair. Its accuracy for teams that lost is same as the accuracy for teams that won.\n",
    "\n",
    "Alternative hypothesis: Our model is unfair. Its accuracy for teams that lost is NOT the same as the accuracy for teams that won.\n",
    "\n",
    "Test statistics: The difference in R^2 between the groups.\n",
    "\n",
    "After performing the permutation test, the result p-value we got is 1.0, which is larger than the 0.05 significance level. Consequently, we fail to reject the null hypothesis. This outcome implies that our model predicts players from both groups with statistically similar accuracy levels. Consequently, our model appears to be fair, exhibiting no discernible bias towards one group over the other based on the specified criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline: apply OneHotEncoder for categorical features and StandardScaler for numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "        ('num', StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline that first preprocesses the data then applies a Random Forest regressor\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(max_depth=10, min_samples_split=5, n_estimators=100, random_state=1))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(predict_df.drop(columns=['visionscore']), predict_df['visionscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(predict_df.drop(columns=['visionscore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_analy = predict_df.copy()\n",
    "\n",
    "fair_analy['vision_pred'] =  y_pred\n",
    "\n",
    "fair_analy = fair_analy[['result','vision_pred','visionscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_analy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "n_repetitions = 500\n",
    "\n",
    "# Step 0: Compute the observed difference\n",
    "# Compute R² for each group using the original predictions.\n",
    "group_r2_obs = fair_analy.groupby('result').apply(\n",
    "    lambda group: r2_score(group['visionscore'], group['vision_pred']),\n",
    "    include_groups=False\n",
    ")\n",
    "observed_diff = abs(group_r2_obs.loc[True] - group_r2_obs.loc[False])\n",
    "print(\"Observed difference:\", observed_diff)\n",
    "\n",
    "# Step 1: Permutation test\n",
    "differences = []\n",
    "for _ in range(n_repetitions):\n",
    "    # Shuffle the predictions and assign to a new column.\n",
    "    with_shuffled = fair_analy.assign(\n",
    "        Shuffled_vision=np.random.permutation(fair_analy['vision_pred'])\n",
    "    )\n",
    "    \n",
    "    # Compute the R² for each group using the shuffled predictions.\n",
    "    group_r2 = with_shuffled.groupby('result').apply(\n",
    "        lambda group: r2_score(group['visionscore'], group['Shuffled_vision']),\n",
    "        include_groups=False\n",
    "    )\n",
    "    \n",
    "    # Calculate the absolute difference between the R² scores.\n",
    "    diff = abs(group_r2.loc[True] - group_r2.loc[False])\n",
    "    differences.append(diff)\n",
    "\n",
    "# Convert list to numpy array for easier comparison.\n",
    "differences = np.array(differences)\n",
    "\n",
    "# Step 2: Compute the p-value\n",
    "# p-value is the fraction of permutations where the permuted difference\n",
    "# is as large or larger than the observed difference.\n",
    "p_value = np.mean(differences >= observed_diff)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
